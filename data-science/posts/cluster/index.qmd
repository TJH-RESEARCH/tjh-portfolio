---
title: "Clustering for Dimension Reduction"
description: "Finding hidden patterns in social science data using clustering"
author:
  - name: Thomas Hodges
    orcid: 0000-0002-5184-7346
date: 2025-06-03
categories: 
  - Unsupervised Learning
draft: false
---

## Project Summary

Ever heard the phrase "more money, more problems?" A similar idea exists in data science: more data, more problems. There are a few ways this comes about. Having too many cases (e.g., rows, observations) takes a lot of computing power, and can sometimes require different sets of tools and analyses. But having too many variables (e.g., columns, features) can also be a problem.

That's the case with a set of variables from a survey I collected with some veterans. I want to know how veteran identities affects a person's integration into civilian life. Conveniently, there is a validated measure of veterans identity: the "Warrior Identity Scale." Unconveniently, it measures 7 different aspects of military identity, each of which is considered a separate variable.

This presented me with the "curse of dimensionality," having more dimensions to the data than I can easily use. Several options were available. First, I could have used all 7 of the variables. Second, I could have chosen 1 or more of the variables as the most important variables. There are problems with both of these options. Using all the variables leads to a messier model. It has lots of predictor variables — all 7 of the Warrior Identity Scale measures — but it is hard to make sense of how those predictor variables are related. And we should expect some sort of relationship(s). After all, these are all aspects of the same phenomenon, identity.

The second option would be to select 1 or more of the identity variables. The problem is this becomes picking and choosing which identity variables matter if it is not done in regards to a particular theory. There are theories to choose from, no doubt, but again we get into the position of picking and choosing theories without justification for preferring one over the other. Analyses of this kind can still be valuable, but so too can the approach that I took: learning from the data to reduce the number of dimensions. To do so, I used **clustering** to uncover latent groups of veterans based on their identity.

The complete [analysis code is available on GitHub](https://github.com/TJH-RESEARCH/identity-reintegration). A [paper detailing the analysis](../research/working-papers/identity-reintegration/index.qmd) is currently in the works. I presented a [poster based on this work](../../talks.index) at the Atlanta VA. Below you can find a walkthrough of the data analysis.

## Skills Demonstrated

1.  Machine Learning
2.  Unsupervised Learning
3.  Regression analysis

## Real-World Applications

### Dimension Reduction

Clustering analysis can be used to address the "curse of dimensionality." It is one tool for "dimensional reduction," reducing the number of variables you have.

I used **clustering** to uncover latent groups of veterans based on their identity. Clustering analysis is an type of unsupervised learning. It finds groups of variables in multiple dimensions. That is, if on a 2 dimensional plot, we could circle apparent groups:

```{r}
library(tidyverse)
# Make some example data:
tibble(x = c(1,2,3,1,2,3,9,7,8),
       y = c(2,1,2,6,8,7,5,6,4)
       ) %>% 
# Graph a scatter plot:
  ggplot(aes(x, y)) +
  geom_point() +
  scale_x_continuous(breaks = seq(0,10,2), limits = c(0,10)) +
  scale_y_continuous(breaks = seq(0,10,2), limits = c(0,10)) +
  theme_classic() +
# Draw circles around the clusters
  ggforce::geom_mark_circle(x = 2, y = 1.8, r = .14, color = "blue") +
  ggforce::geom_mark_circle(x = 1.9, y = 6.8, r = .14, color = "green") +
  ggforce::geom_mark_circle(x = 7.9, y = 5.15, r = .14, color = "red")
```

The same could be done with a 3D plot

```{r}
library(rgl)
data <- 
  tibble(x = c(1,2,3,1,2,3,9,7,8),
       y = c(2,1,2,6,8,7,5,6,4),
       z = c(1,2,1,8,7,7,3,4,4),
       color = c(rep('blue',3),rep('green', 3), rep('red', 3))
       )

plot3d(x = data$x, y = data$y, z = data$z, 
       col = data$color, 
       type = "s",
       xlab = 'x', ylab = "y", zlab = "z")
rglwidget()

```

While we cannot visualize past three dimensions, mathematically we can use the same clustering algorithms in more than three dimensions.

Under the hood, the algorithm is trying to find the number of clusters that most reduces within cluster variance. In other words, it tries to find the multidimensional distance from each data point to every other data point in its cluster.

The more clusters chosen, the lower the variance, but having the number of clusters equal to the number of data points (k = n) does us no help in reducing dimensions. Ultimately, we have to choose which solution (i.e., number of clusters) to choose, and we need to balance parsimony with fit.

### Data Mining Hidden patterns

This approach of learning from the data can be called **data mining**....Another way of thinking about it is **unsupervised learning**, a form of machine learning where we use a model to categorize data without having a "true" category to compare the model categorizations to. In other words, there are no "true" configurations of veterans identity that have been named and observed in the data. We are trying to uncover these unlabeled "latent" groupings in the data.

In the real world...

In this project....

A key issue with unsupervised learning is not having a ground truth to compare the model. No matter how good it fits the data you have, it is not possible to know if clusters corresponds to real groupings.

In the real world....

In this project....

## Key Highlights

### Cluster Analysis

```{r}

library(factoextra)
library(NbClust)

set.seed(10001)

# Select WIS Data ---------------------------------------------------------
data_cluster_wis <- 
  data %>% 
  select(starts_with('wis') & ends_with('total') & !wis_total) %>% 
  scale()


# Determine the number of clusters ----------------------------------------


# Elbow method
plot_elbow <-  
fviz_nbclust(data_cluster_wis, kmeans, method = "wss") +
    geom_vline(xintercept = 3, linetype = 2)+
    labs(subtitle = "k-Means Clustering: Elbow method suggests 3-cluster solution")

ggsave(plot = plot_elbow,
       path = here::here('output/figures'),
       filename = 'elbow_plot.jpg'
      )

# Silhouette method
plot_silhouette <-
  fviz_nbclust(data_cluster_wis, kmeans, method = "silhouette")+
    labs(subtitle = "k-Means Clustering: Silhouette method suggests 2-cluster solution")

ggsave(plot = plot_silhouette,
       path = here::here('output/figures'),
       filename = 'silhouette_plot.jpg'
)

# Gap statistic
plot_gap_stat <-
  fviz_nbclust(data_cluster_wis, 
               kmeans, 
               nstart = 25,  
               print.summary = T, 
               method = "gap_stat", 
               nboot = 500)  +
   labs(subtitle = "k-Means Clustering: Gap statistic method")

ggsave(plot = plot_gap_stat,
       path = here::here('output/figures'),
       filename = 'gap_stat_plot.jpg'
)

## Gap statistic suggests 1 cluster....which isn't really a cluster now is it
## Basically, this is an inability to reject the null hypo that the data 
## clusters into latent groups. 


# -------------------------------------------------------------------------
results_kmeans <- 
  NbClust(data = data_cluster_wis, 
        diss = NULL, 
        distance = "euclidean",
        min.nc = 2, 
        max.nc = 15, 
        method = 'kmeans',
        index = 'alllong')

results_kmeans$All.index %>% as.data.frame() %>% tibble() %>% slice(2,3)
results_kmeans$Best.nc

# Limit the number of clusters to compare head-to-head 2 and 3 group solution
results_kmeans_limited = 
  NbClust(data = data_cluster_wis, 
            diss = NULL, 
            distance = "euclidean",
            min.nc = 2, 
            max.nc = 4, 
            method = 'kmeans',
            index = 'alllong')



```

```{r}


plot_profiles <-
  data %>% 
  mutate(wis_skills_total = wis_skills_total / 3,
         wis_centrality_total = wis_centrality_total / 4,
         wis_connection_total = wis_connection_total / 3,
         wis_family_total = wis_family_total / 3,
         wis_interdependent_total = wis_interdependent_total / 7,
         wis_private_regard_total = wis_private_regard_total / 7,
         wis_public_regard_total = wis_public_regard_total / 4) %>% 
  select(wis_skills_total,
         wis_centrality_total,
         wis_connection_total,
         wis_family_total,
         wis_interdependent_total,
         wis_private_regard_total,
         wis_public_regard_total,
         cluster) %>% 
  group_by(cluster) %>% 
  mutate(cluster = factor(cluster)) %>%
  summarise(across(everything(), ~ mean(.x))) %>% 
  pivot_longer(!cluster) %>% 
  ggplot(
    aes(
      name, 
      value, 
      color = cluster,
      group = cluster)) + 
  geom_point(
    aes(
      shape = cluster), 
    size = 4) + 
  geom_line(
    aes(
      linetype = cluster)) +
  scale_color_manual(values = c('#440154', '#3b528b', '#5ec962')) +
  #scale_color_viridis(option = 'C', discrete = TRUE) +
  theme_classic() +
  labs(title = paste0('Military Identity by Latent Groups'), 
       x = 'Aspect of Military Identity', 
       y = 'Identity (mean item score)') + 
  theme(axis.text.x = element_text(angle = -30, vjust = 1, hjust = 0)) +
  labs(color = 'Cluster',
       shape = 'Cluster',
       linetype = 'Cluster') +
  scale_x_discrete(
  labels = c('Centrality', 
             'Connection',
             'Family',
             'Interdependence',
             'Private Regard',
             'Public Regard',
             'Skills')
  ) +
  theme(axis.text = element_text(size = 11),
        text = element_text(size = 14))

plot_profiles %>% print()

ggsave(plot = plot_profiles,
       filename = paste0('output/figures/profiles-identity-', clustering, '.jpg'))
 
```

### Validating Clusters

A key issue with unsupervised learning is how to externally validate the clusters. How do we know if these classifications are real or just an artifact of the data?

In supervised learning, validation is easier. You use the model to make some predictions on data it wasn't trained on. Then you calculate how accurate the predictions were. With unsupervised learning, we have no idea how accurate we are. Instead, we need to validate the categories in different ways. In this project, I used two different validation methods.

First, the model should have some "predictive" validity. That is, the clusters should be able to predict other variables. For this project, veterans identity should predict how well they reintegrate into civilian society. Using the clusters as a predictor variable, I fit a linear regression model to a measure of reintegration. Here were the results:\

```{r}

# MCARM TOTAL --------------------------------------------------------------
model_mcarm_1 <- data %>% lm(mcarm_total ~ cluster, .)
model_mcarm_2 <- 
  data %>% 
  lm(mcarm_total ~ 
       cluster +
       race_white + 
       race_black + 
       sex_male +
       enlisted +
       service_era_post_911 + 
       service_era_vietnam + 
       service_era_persian_gulf +
       military_exp_combat +
       n_deploy +
       branch_air_force +
       branch_marines +
       branch_navy, .)
aov_mcarm_1 <- aov(model_mcarm_1)
aov_mcarm_1 <- aov(model_mcarm_2)

```

```{r}


bind_rows(
model_civilians_2 %>% 
  broom::tidy(conf.int = T, conf.level = 0.95) %>% 
  mutate(se_robust = as.numeric(coeftest_civilians_2[,2])) %>% 
  filter(term == 'clusterLower Identity' |
           term == 'clusterHigher Identity') %>% 
  mutate(outcome = 'Civilians') %>% 
  mutate(term = if_else(term == 'clusterLower Identity',
                        'Lower: Civilians', 
                        'Higher: Civilians'
  )), 


model_help_seeking_2 %>% 
  broom::tidy(conf.int = T, conf.level = 0.95) %>% 
  mutate(se_robust = as.numeric(coeftest_help_seeking_2[,2])) %>% 
  filter(term == 'clusterLower Identity' |
           term == 'clusterHigher Identity') %>% 
  mutate(outcome = 'Help Seeking') %>% 
  mutate(term = if_else(term == 'clusterLower Identity',
                        'Lower: Help Seeking', 
                        'Higher: Help Seeking'
  )), 


model_purpose_2 %>% 
  broom::tidy(conf.int = T, conf.level = 0.95) %>% 
  mutate(se_robust = as.numeric(coeftest_purpose_2[,2])) %>% 
  filter(term == 'clusterLower Identity' |
           term == 'clusterHigher Identity') %>% 
  mutate(outcome = 'Purpose') %>% 
  mutate(term = if_else(term == 'clusterLower Identity',
                        'Lower: Purpose', 
                        'Higher: Purpose'
  )), 



model_regiment_2 %>% 
  broom::tidy(conf.int = T, conf.level = 0.95) %>% 
  mutate(se_robust = as.numeric(coeftest_regiment_2[,2])) %>% 
  filter(term == 'clusterLower Identity' |
           term == 'clusterHigher Identity') %>% 
  mutate(outcome = 'Regimnetation') %>% 
  mutate(term = if_else(term == 'clusterLower Identity',
                        'Lower: Regimentation', 
                        'Higher: Regimentation'
  )), 


model_resent_2 %>% 
  broom::tidy(conf.int = T, conf.level = 0.95) %>% 
  mutate(se_robust = as.numeric(coeftest_resent_2[,2])) %>% 
  filter(term == 'clusterLower Identity' |
           term == 'clusterHigher Identity') %>% 
  mutate(outcome = 'Resentment') %>% 
  mutate(term = if_else(term == 'clusterLower Identity',
                        'Lower: Resentment', 
                        'Higher: Resentment'
  )) 

) %>% 
arrange(outcome) %>% 
  ggplot(aes(x = estimate, 
             y = term, 
             xmin = (estimate - 2 * se_robust),
             xmax = (estimate + 2 * se_robust),
             color = outcome,
             shape = outcome)) +
  scale_color_manual(values = c('#440154', 
                                  '#3b528b',
                                  '#21908C',
                                  '#5ec962',
                                  '#C7E020')) +
  geom_pointrange(size = 1.5, linewidth = 1.5) +
  #geom_vline(aes(xintercept = 0), linetype = 2) +
  theme_classic() +
  theme(axis.text = element_text(size = 14),
        text = element_text(size = 14)
  ) +
  xlab('Total') +
  ylab('') +
  scale_y_discrete( 
    labels = c(
      
      `Lower: Resentment` = 'Lower Identity', 
      `Higher: Resentment` = 'Higher Identity', 
      
      `Lower: Regimentation` = 'Lower Identity', 
      `Higher: Regimentation` = 'Higher Identity',
      
      `Lower: Purpose` = 'Lower Identity', 
      `Higher: Purpose` = 'Higher Identity', 
      
      `Lower: Help Seeking` = 'Lower Identity', 
      `Higher: Help Seeking` = 'Higher Identity', 
      
      `Lower: Civilians` = 'Lower Identity', 
      `Higher: Civilians` = 'Higher Identity'
      
    ),
    limits = c(
      'Lower: Resentment', 
      'Higher: Resentment', 
      
      'Lower: Regimentation', 
      'Higher: Regimentation',
      
      'Lower: Purpose', 
      'Higher: Purpose', 
      
      'Lower: Help Seeking', 
      'Higher: Help Seeking', 
      
      'Lower: Civilians', 
      'Higher: Civilians'
      
    ) 
  ) +
  theme(legend.position = 'none')








# Total -------------------------------------------------------------------


model_mcarm_2 %>% 
  broom::tidy(conf.int = T, conf.level = 0.95) %>% 
  
  # Add robust standard errors
  mutate(se_robust = as.numeric(coeftest_mcarm_2[,2])) %>% 
  filter(term == 'clusterLower Identity' |
           term == 'clusterHigher Identity') %>% 
  mutate(outcome = 'Rentegration') %>% 
  mutate(term = if_else(term == 'clusterLower Identity',
                        'Lower: Reintegration', 
                        'Higher: Reintegration'
  ))
```

Second, the cluster groupings should be replicable in other data sets. That is, if we collect new data, we should find similar groupings if the grouping are real. With this in mind, I collected some more data with a new survey. Then, I repeated the clustering in the new data set.

\[example\]
